{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adadelta,Adam # I believe Adam this is better optimizer for our case\n",
    "from keras.preprocessing.image import ImageDataGenerator # to augmenting our images for increasing accuracy\n",
    "from sklearn.model_selection import train_test_split # to split our train data into train and validation sets\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "np.random.seed(13) # My lucky number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "030b1ebf761aa450ce18b253813433ca5293c2fc"
   },
   "outputs": [],
   "source": [
    "num_classes = 10 # We have 10 digits to identify\n",
    "batch_size = 256 # Handle 256 pictures at each round\n",
    "epochs = 10 # 10 Epoch is enough for %99.4 Accuracy!!!!\n",
    "img_rows, img_cols = 28, 28 # Input image dimensions 28x28 pixels\n",
    "input_shape = (img_rows, img_cols,1) # We'll use this while building layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "dc20a3a5e6d491e98be7d0ff3aaa6eec7bdc123b"
   },
   "outputs": [],
   "source": [
    "# Load some date to rock'n roll\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "23e65adaf0ef381576c5597aebb6ce5dcc466174"
   },
   "outputs": [],
   "source": [
    "# Drop the label from the data and move it to real label part\n",
    "y_train = train[\"label\"]\n",
    "x_train = train.drop(labels = [\"label\"],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fc3b21df164c213db201b317ba453c8914dd2200"
   },
   "outputs": [],
   "source": [
    "# Normalize both sets\n",
    "x_train /= 255\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "922cb2c73388a6ec4b368b032f133b2c4c9783c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 train samples\n",
      "28000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0], 'train samples')\n",
    "print(test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4ac625840bb33a39580405985955d9076c003d3c"
   },
   "outputs": [],
   "source": [
    "# Images should be in shape of height,width and color channel so it will be 28x28x1\n",
    "x_train = x_train.values.reshape(-1,img_rows,img_cols,1)\n",
    "test = test.values.reshape(-1,img_rows,img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "057065fd2bf1e11bdb9885b746c27452ee21505c"
   },
   "outputs": [],
   "source": [
    "# Class vectors needs to be binary so we use \"to_catogorical\" function of keras utilities for one-hot-encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d1965d067618cee1c84f6ef75461c25840b4b12c"
   },
   "outputs": [],
   "source": [
    "# Lets split our train set into train and validation test sets with my lucky number 13 :)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "1e271e0d37535c7c401a873578ad3dd19b51b133"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer consisting of 32 filters and shape of 5x5 with ReLU activation\n",
    "# We want to preserve more information for followin layers so we start using padding\n",
    "# 'Same' padding tries to pad evenly left and right, but if the amount of columns to be added is odd, it will add the extra column to the right\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = input_shape))\n",
    "BatchNormalization(axis=-1)\n",
    "# Add convolutional layer consisting of 32 filters and shape of 5x5 with ReLU activation\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "\n",
    "# Add Maxpool layer with the shape of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "BatchNormalization(axis=-1)\n",
    "# Dropping %25 of neurons\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add convolutional layer consisting of 64 filters and shape of 3x3 with ReLU activation\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "# Add convolutional layer consisting of 64 filters and shape of 3x3 with ReLU activation\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "# Add convolutional layer consisting of 64 filters and shape of 3x3 with ReLU activation\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "# Add Maxpool layer with the shape of 2x2 and strides for controlling convolutions over input volume\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "# Dropping %25 of neurons\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# To be able to merge into fully connected layer we have to flatten\n",
    "model.add(Flatten())\n",
    "BatchNormalization()\n",
    "# Adding fully connected layer with 256 ReLU activated neurons\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "BatchNormalization()\n",
    "# Dropping %50 of neurons\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Lets add softmax activated neurons as much as number of classes\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "d66b221d286725527050b22d6942ab59693ed6fe"
   },
   "outputs": [],
   "source": [
    "# Adam (my favorite) inorder to get over %99 before 5th \n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "7f35afd55620e744260b19f75f513fd5df90e4b9"
   },
   "outputs": [],
   "source": [
    "# Compile the model with loss and metrics\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "3b5468b524407441d9731b87e97bb010b7cded69"
   },
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation more detail: https://keras.io/preprocessing/image/\n",
    "datagen = ImageDataGenerator(rotation_range=10, zoom_range = 0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "8b7f141a76736640c752920eefa6062bcade357d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 6s - loss: 0.0400 - acc: 0.9881 - val_loss: 0.0177 - val_acc: 0.9948\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.0426 - acc: 0.9877 - val_loss: 0.0174 - val_acc: 0.9945\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.0393 - acc: 0.9885 - val_loss: 0.0152 - val_acc: 0.9948\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.0373 - acc: 0.9883 - val_loss: 0.0180 - val_acc: 0.9948\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.0402 - acc: 0.9878 - val_loss: 0.0190 - val_acc: 0.9938\n",
      "Epoch 6/10\n",
      " - 6s - loss: 0.0364 - acc: 0.9884 - val_loss: 0.0152 - val_acc: 0.9960\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.0354 - acc: 0.9892 - val_loss: 0.0154 - val_acc: 0.9952\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.0361 - acc: 0.9894 - val_loss: 0.0144 - val_acc: 0.9955\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0364 - acc: 0.9885 - val_loss: 0.0163 - val_acc: 0.9948\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.0338 - acc: 0.9893 - val_loss: 0.0157 - val_acc: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb5549eb38>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start model training with the batch size\n",
    "model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                    epochs = epochs, validation_data = (x_test,y_test),\n",
    "                    verbose = 2, steps_per_epoch=x_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "64720957674b4dcd0d5305e48cc0a35e405b0d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.015744022748355443\n",
      "Test accuracy: 0.9959523809523809\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy and loss over validation set\n",
    "score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
